# ğŸ Hive Backend

A Reddit-like backend with content verification powered by web scraping and a Gemini-based RAG pipeline.

## ğŸ“– Project Description

Hive provides a FastAPI backend for posts, media storage, and user auth (Supabase), with automatic verification of post content via a RAG pipeline.

## ğŸ“‚ Folder Structure

```
Hive_Backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routers/
â”‚   â”‚       â”œâ”€â”€ posts.py           # posts CRUD, reactions, listing
â”‚   â”‚       â”œâ”€â”€ storage.py               # uploads to Supabase Storage
â”‚   â”‚       â””â”€â”€ auth.py             # Supabase OAuth, JWT auth helpers
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ config.py                    # settings (Supabase, Gemini, Chroma, etc.)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag.py                       # RagRequest/Response enums
â”‚   â”‚   â”œâ”€â”€ post.py                   # User, Post, Comment, ShowPost, tokens
â”‚   â”‚   â””â”€â”€ scraper.py                   # ScraperResult
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”‚   â””â”€â”€ scraper_agent/web_scraper.py
â”‚   â”‚   â”œâ”€â”€ search_agent/
â”‚   â”‚   â”‚   â””â”€â”€ search_agent.py
â”‚   â”‚   â””â”€â”€ rag_agent/
â”‚   â”‚       â””â”€â”€ rag_agent.py             # Gemini + Chroma pipeline
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ verification_service.py      # verification orchestration
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ supabase_client.py           # client factory (anon/admin)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_main.py
â”‚   â””â”€â”€ test_supabase_client.py
â”œâ”€â”€ pyproject.toml | poetry.lock | requirements.txt
â”œâ”€â”€ setup_env.py | env.example | README.md
â””â”€â”€ venv/
```

## âš™ï¸ Setup & Installation

### Prerequisites

-   Python 3.13+
-   Supabase project (URL + anon + service role keys)

### Environment Setup

1. Create and activate a virtual environment + install redis (recommended)

    ```bash
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    sudo apt-get install redis-server
    ```

    Or with Poetry:

    ```bash
    pip install poetry
    poetry install
    poetry run uvicorn app.main:app --reload
    ```

2. Environment variables

    ```bash
    python setup_env.py
    # or
    cp env.example .env
    ```

## â–¶ï¸ Running the Server

```bash
sudo service redis-server start
uvicorn app.main:app --reload
```

Server: `http://localhost:8000`

### API Docs

-   Swagger UI: `http://localhost:8000/docs`
-   ReDoc: `http://localhost:8000/redoc`

### Health

-   GET `/` â†’ welcome
-   GET `/health` â†’ service health
-   GET `/config/test` â†’ config probe

## ğŸ” Authentication (Supabase OAuth)

-   GET `/user/login` â†’ Redirect to Google OAuth
-   GET `/user/users/me` â†’ Get current user (requires `Authorization: Bearer <jwt>`)
-   GET `/user/logout` â†’ Sign out

Use the Supabase session JWT as the Bearer token for authenticated routes.

## ğŸ—ƒï¸ Storage

-   POST `/storage/upload/profile-pic` â†’ upload profile picture, updates `users.profile_pic_url`

## ğŸ“ Posts API

Prefix: `/post`

-   POST `/` â†’ create post (body: `Post`), enqueues verification
-   GET `/` â†’ list all posts
-   GET `/users/{uid}/posts` â†’ list posts by user
-   GET `/{pid}` â†’ get one post
-   PUT `/{pid}` â†’ update post (owner only)
-   DELETE `/{pid}` â†’ delete post (owner only)
-   POST `/{pid}/like` â†’ increment likes
-   POST `/{pid}/dislike` â†’ increment dislikes

## ğŸ§  Verification Pipeline

-   Orchestrated in `app/services/verification_service.py` using:
    -   `search_agent.get_links` to find sources
    -   `scraper_agent.WebScraper` to fetch content
    -   `VerificationRAGPipeline` (Gemini + Chroma) to verify/classify

`VerificationRAGPipeline.verify(RagRequest)` returns:

```json
{
    "status": "verified | unverified | personal_opinion | misinformation | factual_error | other",
    "confidence": 0.0,
    "answer": "...",
    "supporting_context": ["..."],
    "rationale": "...",
    "metadata": { "post_id": "..." }
}
```

## ğŸ§± Models (Pydantic)

-   `app/models/schemas.py`
    -   `User`, `Post`, `Comment`, `ShowPost`, `Token`, `TokenData`
    -   `PostContentRequest`, `PostVerificationRequest`
-   `app/models/rag.py`
    -   `RagRequest`, `RagResponse`
-   `app/models/scraper.py`
    -   `ScraperResult`

## ğŸ› ï¸ Configuration

`app/core/config.py` exposes `settings` with nested sections:

-   Supabase: `SUPABASE_URL`, `SUPABASE_ANON_KEY`, `SUPABASE_SERVICE_ROLE_KEY`
-   Gemini: `GEMINI_API_KEY`, `GEMINI_MODEL`, `GEMINI_EMBED_MODEL`, `GEMINI_MAX_TOKENS`, `GEMINI_TEMPERATURE`, `GOOGLE_CUSTOM_SEARCH_API`, `SEARCH_ENGINE_ID`
-   Vector DB (Chroma): `CHROMA_PERSIST_PATH`, `CHROMA_COLLECTION`
-   API: `NEWS_API_KEY`, `FACT_CHECK_API_KEY`
-   Security: `SECRET_KEY`, `ALGORITHM`, token expiries

## ğŸ”§ Environment Variables (.env)

```env
# Supabase
SUPABASE_URL=...
SUPABASE_ANON_KEY=...
SUPABASE_SERVICE_ROLE_KEY=...

# Gemini
GEMINI_API_KEY=...
GEMINI_MODEL=gemini-pro
GEMINI_EMBED_MODEL=models/embedding-001
GEMINI_MAX_TOKENS=1000
GEMINI_TEMPERATURE=0.7
GOOGLE_CUSTOM_SEARCH_API=...
SEARCH_ENGINE_ID=...

# Chroma
CHROMA_PERSIST_PATH=.chroma
CHROMA_COLLECTION=verification_docs

# API
NEWS_API_KEY=...
FACT_CHECK_API_KEY=...

# Security
SECRET_KEY=change-me
```

## ğŸ§ª Testing

```bash
pytest
```

## ğŸ“„ Notes

-   Uses Redis + RQ for async verification task enqueue from post creation.
-   Supabase client is centralized in `app/utils/supabase_client.py`.
